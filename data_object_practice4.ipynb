{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "data_object_practice.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LiliannLucas/Practices/blob/main/data_object_practice4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FO3nZUM5q1lo"
      },
      "source": [
        "You do have the below text:\n",
        "\n",
        "**text_sample** = \"Web scraping is the process of collecting and parsing data from the web. The Python community has come up with some pretty powerful web scrapping tools. However, many modern websites are dynamic, in which the content is loaded and populated using client JavaScript. Therefore, some extra setups are required in order to scrape data from JavaScript webpages.\n",
        "In this article, you’ll learn how to scrape tables from a JavaScript webpage using Selenium, BeautifulSoup, and Pandas. Scrapping tables from a webpage with Python often requires no more than the use of Pandas read_html() function to reach the goal. However, a lot of modern websites are dynamic, in which the content is loaded and populated using client JavaScript. Therefore, examples using Pandas read_html() will not work without some extra setups.\n",
        "Let’s take a look at an example. Suppose we want to scrape tables from the following article, published in Nanoscale Advances journal.\"\n",
        "\n",
        "\n",
        "**text_sample2** = \"Running the script shows an error ValueError: No tables found. This is because Pandas read_html() function searches for table elements and can’t find any from the webpage. If we look at the page source and search for table, it shows 0 result. Running the script shows an error “ValueError: No tables found”. This is because Pandas read_html() function searches for <table> elements and can’t find any from the webpage.\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WXKOq0-HrEaT"
      },
      "source": [
        "1. make a **dictionary** variable of each word and its occurence. Make sure you do clean speical characters. like \",\", \"(\", \"{\"..... and\n",
        "e.g. \"The\" : 3, \"read_html\" : 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1E8OPnMxqwRr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67192e06-34ad-44a2-c03e-9f5a68a3ec0c"
      },
      "source": [
        "text_sample = \"Web scraping is the process of collecting and parsing data from the web. The Python community has come up with some pretty powerful web scrapping tools. However, many modern websites are dynamic, in which the content is loaded and populated using client JavaScript. Therefore, some extra setups are required in order to scrape data from JavaScript webpages. In this article, you’ll learn how to scrape tables from a JavaScript webpage using Selenium, BeautifulSoup, and Pandas. Scrapping tables from a webpage with Python often requires no more than the use of Pandas read_html() function to reach the goal. However, a lot of modern websites are dynamic, in which the content is loaded and populated using client JavaScript. Therefore, examples using Pandas read_html() will not work without some extra setups. Let’s take a look at an example. Suppose we want to scrape tables from the following article, published in Nanoscale Advances journal.\"\n",
        "\n",
        "text_sample2 = \"Running the script shows an error ValueError: No tables found. This is because Pandas read_html() function searches for table elements and can’t find any from the webpage. If we look at the page source and search for table, it shows 0 result. Running the script shows an error “ValueError: No tables found”. This is because Pandas read_html() function searches for elements and can’t find any from the webpage.\"\n",
        "\n",
        "\n",
        "s1 = text_sample.lower()\n",
        "\n",
        "s2 = text_sample2.lower()\n",
        "\n",
        "\n",
        "\n",
        "pun = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~'''\n",
        "\n",
        "for i in pun:\n",
        "  s1 = s1.replace(i, '')\n",
        "  s2 = s2.replace(i, '')\n",
        "\n",
        "# print(\"s:\", s1, s2)\n",
        "\n",
        "e1 = s1.split(' ')\n",
        "e2 = s2.split(' ')\n",
        "\n",
        "# print(\"e:\", e, e2)\n",
        "\n",
        "e = e1 + e2\n",
        "\n",
        "\n",
        "\n",
        "# for i in e:\n",
        "#     i, e.count(i)\n",
        "#     dict = {\"word\": i, \"count\": e.count(i)}\n",
        "\n",
        "# print(dict)\n",
        "\n",
        "a = {}\n",
        "\n",
        "for i in e1:\n",
        "  if a.get(i):\n",
        "    v = a[i]\n",
        "    a[i] = v + 1\n",
        "  else:\n",
        "    a[i] =  1\n",
        "\n",
        "b = {}\n",
        "\n",
        "for i in e2:\n",
        "  if b.get(i):\n",
        "    v = b[i]\n",
        "    b[i] = v + 1\n",
        "  else:\n",
        "    b[i] =  1\n",
        "\n",
        "print(a)\n",
        "print(b)\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'web': 3, 'scraping': 1, 'is': 3, 'the': 8, 'process': 1, 'of': 3, 'collecting': 1, 'and': 4, 'parsing': 1, 'data': 2, 'from': 5, 'python': 2, 'community': 1, 'has': 1, 'come': 1, 'up': 1, 'with': 2, 'some': 3, 'pretty': 1, 'powerful': 1, 'scrapping': 2, 'tools': 1, 'however': 2, 'many': 1, 'modern': 2, 'websites': 2, 'are': 3, 'dynamic': 2, 'in': 5, 'which': 2, 'content': 2, 'loaded': 2, 'populated': 2, 'using': 4, 'client': 2, 'javascript': 4, 'therefore': 2, 'extra': 2, 'setups': 2, 'required': 1, 'order': 1, 'to': 4, 'scrape': 3, 'webpages': 1, 'this': 1, 'article': 2, 'you’ll': 1, 'learn': 1, 'how': 1, 'tables': 3, 'a': 4, 'webpage': 2, 'selenium': 1, 'beautifulsoup': 1, 'pandas': 3, 'often': 1, 'requires': 1, 'no': 1, 'more': 1, 'than': 1, 'use': 1, 'readhtml': 2, 'function': 1, 'reach': 1, 'goal': 1, 'lot': 1, 'examples': 1, 'will': 1, 'not': 1, 'work': 1, 'without': 1, 'let’s': 1, 'take': 1, 'look': 1, 'at': 1, 'an': 1, 'example': 1, 'suppose': 1, 'we': 1, 'want': 1, 'following': 1, 'published': 1, 'nanoscale': 1, 'advances': 1, 'journal': 1}\n",
            "{'running': 2, 'the': 5, 'script': 2, 'shows': 3, 'an': 2, 'error': 2, 'valueerror': 1, 'no': 2, 'tables': 2, 'found': 1, 'this': 2, 'is': 2, 'because': 2, 'pandas': 2, 'readhtml': 2, 'function': 2, 'searches': 2, 'for': 3, 'table': 2, 'elements': 2, 'and': 3, 'can’t': 2, 'find': 2, 'any': 2, 'from': 2, 'webpage': 2, 'if': 1, 'we': 1, 'look': 1, 'at': 1, 'page': 1, 'source': 1, 'search': 1, 'it': 1, '0': 1, 'result': 1, '“valueerror': 1, 'found”': 1}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "InRbK16SsMpl"
      },
      "source": [
        "2. from the dictionary variable, find its length is greater than 5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nfwS0ySktKfY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ae06504-da86-488e-bb68-73ef03c3abe4"
      },
      "source": [
        "a\n",
        "b\n",
        "\n",
        "for e in a:\n",
        "  if a.get(e):\n",
        "    if len(e) > 5:\n",
        "      print(e, len(e))\n",
        "\n",
        "for e in b:\n",
        "  if b.get(e):\n",
        "    if len(e) > 5:\n",
        "      print(e, len(e))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "scraping 8\n",
            "process 7\n",
            "collecting 10\n",
            "parsing 7\n",
            "python 6\n",
            "community 9\n",
            "pretty 6\n",
            "powerful 8\n",
            "scrapping 9\n",
            "however 7\n",
            "modern 6\n",
            "websites 8\n",
            "dynamic 7\n",
            "content 7\n",
            "loaded 6\n",
            "populated 9\n",
            "client 6\n",
            "javascript 10\n",
            "therefore 9\n",
            "setups 6\n",
            "required 8\n",
            "scrape 6\n",
            "webpages 8\n",
            "article 7\n",
            "you’ll 6\n",
            "tables 6\n",
            "webpage 7\n",
            "selenium 8\n",
            "beautifulsoup 13\n",
            "pandas 6\n",
            "requires 8\n",
            "readhtml 8\n",
            "function 8\n",
            "examples 8\n",
            "without 7\n",
            "example 7\n",
            "suppose 7\n",
            "following 9\n",
            "published 9\n",
            "nanoscale 9\n",
            "advances 8\n",
            "journal 7\n",
            "running 7\n",
            "script 6\n",
            "valueerror 10\n",
            "tables 6\n",
            "because 7\n",
            "pandas 6\n",
            "readhtml 8\n",
            "function 8\n",
            "searches 8\n",
            "elements 8\n",
            "webpage 7\n",
            "source 6\n",
            "search 6\n",
            "result 6\n",
            "“valueerror 11\n",
            "found” 6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J_OEQSNytWiH"
      },
      "source": [
        "3. from the dictionary variable, get all keys"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FuyoogOCtfIX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba2632e5-4eb3-443b-9677-cea48c803303"
      },
      "source": [
        "a\n",
        "print(a.keys())\n",
        "print(list(a.keys()))\n",
        "\n",
        "\n",
        "b\n",
        "print(b.keys())"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['web', 'scraping', 'is', 'the', 'process', 'of', 'collecting', 'and', 'parsing', 'data', 'from', 'python', 'community', 'has', 'come', 'up', 'with', 'some', 'pretty', 'powerful', 'scrapping', 'tools', 'however', 'many', 'modern', 'websites', 'are', 'dynamic', 'in', 'which', 'content', 'loaded', 'populated', 'using', 'client', 'javascript', 'therefore', 'extra', 'setups', 'required', 'order', 'to', 'scrape', 'webpages', 'this', 'article', 'you’ll', 'learn', 'how', 'tables', 'a', 'webpage', 'selenium', 'beautifulsoup', 'pandas', 'often', 'requires', 'no', 'more', 'than', 'use', 'readhtml', 'function', 'reach', 'goal', 'lot', 'examples', 'will', 'not', 'work', 'without', 'let’s', 'take', 'look', 'at', 'an', 'example', 'suppose', 'we', 'want', 'following', 'published', 'nanoscale', 'advances', 'journal'])\n",
            "['web', 'scraping', 'is', 'the', 'process', 'of', 'collecting', 'and', 'parsing', 'data', 'from', 'python', 'community', 'has', 'come', 'up', 'with', 'some', 'pretty', 'powerful', 'scrapping', 'tools', 'however', 'many', 'modern', 'websites', 'are', 'dynamic', 'in', 'which', 'content', 'loaded', 'populated', 'using', 'client', 'javascript', 'therefore', 'extra', 'setups', 'required', 'order', 'to', 'scrape', 'webpages', 'this', 'article', 'you’ll', 'learn', 'how', 'tables', 'a', 'webpage', 'selenium', 'beautifulsoup', 'pandas', 'often', 'requires', 'no', 'more', 'than', 'use', 'readhtml', 'function', 'reach', 'goal', 'lot', 'examples', 'will', 'not', 'work', 'without', 'let’s', 'take', 'look', 'at', 'an', 'example', 'suppose', 'we', 'want', 'following', 'published', 'nanoscale', 'advances', 'journal']\n",
            "dict_keys(['running', 'the', 'script', 'shows', 'an', 'error', 'valueerror', 'no', 'tables', 'found', 'this', 'is', 'because', 'pandas', 'readhtml', 'function', 'searches', 'for', 'table', 'elements', 'and', 'can’t', 'find', 'any', 'from', 'webpage', 'if', 'we', 'look', 'at', 'page', 'source', 'search', 'it', '0', 'result', '“valueerror', 'found”'])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mu6bSunRtfpC"
      },
      "source": [
        "4. from the dictionary variable, get all values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t1sRjmPKtjqj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03cbdf76-f125-47c6-8920-9633d5310454"
      },
      "source": [
        "a\n",
        "print(a.values())\n",
        "\n",
        "\n",
        "b\n",
        "print(b.values())"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_values([3, 1, 3, 8, 1, 3, 1, 4, 1, 2, 5, 2, 1, 1, 1, 1, 2, 3, 1, 1, 2, 1, 2, 1, 2, 2, 3, 2, 5, 2, 2, 2, 2, 4, 2, 4, 2, 2, 2, 1, 1, 4, 3, 1, 1, 2, 1, 1, 1, 3, 4, 2, 1, 1, 3, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
            "dict_values([2, 5, 2, 3, 2, 2, 1, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 3, 2, 2, 3, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gL3TCmuWtk0Z"
      },
      "source": [
        "5. what is the key and its value from the dictionary variable where it is located last - 3 location"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F69dRXNVt2Xm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "433fcb6b-d2cc-42d9-b445-ad6483f849f0"
      },
      "source": [
        "a\n",
        "# print(list(a.keys()))\n",
        "lisa = list(a.keys())\n",
        "\n",
        "print(a.get(lisa[-3]))\n",
        "print(lisa[-3])\n",
        "\n",
        "\n",
        "# print(a.keys[-3])\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "nanoscale\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bYyMH54St3J3"
      },
      "source": [
        "6. sort the dictionary variable from its values in descending order"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_hNKc6AuHCb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79374efe-0f52-4b69-f47e-9af92ad06fec"
      },
      "source": [
        "import operator\n",
        "\n",
        "sorted_a = dict(sorted(a.items(), key=operator.itemgetter(1),reverse=True))\n",
        "print(sorted_a)\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'the': 8, 'from': 5, 'in': 5, 'and': 4, 'using': 4, 'javascript': 4, 'to': 4, 'a': 4, 'web': 3, 'is': 3, 'of': 3, 'some': 3, 'are': 3, 'scrape': 3, 'tables': 3, 'pandas': 3, 'data': 2, 'python': 2, 'with': 2, 'scrapping': 2, 'however': 2, 'modern': 2, 'websites': 2, 'dynamic': 2, 'which': 2, 'content': 2, 'loaded': 2, 'populated': 2, 'client': 2, 'therefore': 2, 'extra': 2, 'setups': 2, 'article': 2, 'webpage': 2, 'readhtml': 2, 'scraping': 1, 'process': 1, 'collecting': 1, 'parsing': 1, 'community': 1, 'has': 1, 'come': 1, 'up': 1, 'pretty': 1, 'powerful': 1, 'tools': 1, 'many': 1, 'required': 1, 'order': 1, 'webpages': 1, 'this': 1, 'you’ll': 1, 'learn': 1, 'how': 1, 'selenium': 1, 'beautifulsoup': 1, 'often': 1, 'requires': 1, 'no': 1, 'more': 1, 'than': 1, 'use': 1, 'function': 1, 'reach': 1, 'goal': 1, 'lot': 1, 'examples': 1, 'will': 1, 'not': 1, 'work': 1, 'without': 1, 'let’s': 1, 'take': 1, 'look': 1, 'at': 1, 'an': 1, 'example': 1, 'suppose': 1, 'we': 1, 'want': 1, 'following': 1, 'published': 1, 'nanoscale': 1, 'advances': 1, 'journal': 1}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Qm2Ax32uJQd"
      },
      "source": [
        "7. sort the dictionary variable from its keys in descending order"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-wES7f95uMRT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b709e13-3bba-4090-a610-ba8646359aa9"
      },
      "source": [
        "a\n",
        "\n",
        "for e in a:\n",
        "  x = sorted(a, reverse=True)\n",
        "\n",
        "print(x)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['you’ll', 'work', 'without', 'with', 'will', 'which', 'websites', 'webpages', 'webpage', 'web', 'we', 'want', 'using', 'use', 'up', 'tools', 'to', 'this', 'therefore', 'the', 'than', 'take', 'tables', 'suppose', 'some', 'setups', 'selenium', 'scrapping', 'scraping', 'scrape', 'requires', 'required', 'readhtml', 'reach', 'python', 'published', 'process', 'pretty', 'powerful', 'populated', 'parsing', 'pandas', 'order', 'often', 'of', 'not', 'no', 'nanoscale', 'more', 'modern', 'many', 'lot', 'look', 'loaded', 'let’s', 'learn', 'journal', 'javascript', 'is', 'in', 'however', 'how', 'has', 'goal', 'function', 'from', 'following', 'extra', 'examples', 'example', 'dynamic', 'data', 'content', 'community', 'come', 'collecting', 'client', 'beautifulsoup', 'at', 'article', 'are', 'and', 'an', 'advances', 'a']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PvMZ4cbouM4j"
      },
      "source": [
        "8. create a set variables from text_sample2. and create a set variables from the dictionary keys."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nRUunQaCug8D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4c2c786-193c-4293-eb79-7ca62e9f0b96"
      },
      "source": [
        "e2\n",
        "\n",
        "set2 = set()\n",
        "\n",
        "set2.update(e2)\n",
        "\n",
        "print(set2)\n",
        "\n",
        "# for x in e2:\n",
        "#   print(str(x))\n",
        "\n",
        "\n",
        "#------------\n",
        "\n",
        "print(a)\n",
        "\n",
        "# z = set2.intersection(a)\n",
        "\n",
        "# print(z)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'readhtml', 'no', 'table', 'elements', 'pandas', 'found', 'search', 'result', 'found”', 'we', 'and', 'for', 'this', 'tables', 'is', 'valueerror', '0', 'source', 'the', 'searches', 'can’t', 'any', 'look', 'page', 'it', '“valueerror', 'an', 'because', 'function', 'error', 'at', 'from', 'shows', 'script', 'find', 'webpage', 'running', 'if'}\n",
            "{'tables', 'is', 'from', 'no', 'readhtml', 'pandas', 'the', 'an', 'we', 'and', 'look', 'webpage', 'this', 'function', 'at'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UtU5pdxGuhgp"
      },
      "source": [
        "9. find intersection of set variables from question 8."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KCQrAiVauqev"
      },
      "source": [
        "z = set2.intersection(a)\n",
        "\n",
        "print(z)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GPwjDObkvJT0"
      },
      "source": [
        "10. find difference from set variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JblrELxevPwp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bcf46cd9-9208-4bb5-e3ee-bdcebbb3f2d0"
      },
      "source": [
        "y = set2.difference(a)\n",
        "\n",
        "print(y)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'table', 'found”', 'result', 'search', 'elements', 'found', 'for', 'valueerror', '0', 'source', 'searches', 'can’t', 'any', 'page', 'it', '“valueerror', 'because', 'error', 'shows', 'script', 'find', 'running', 'if'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dPhonW13vQDJ"
      },
      "source": [
        "11. combine two set varaibles into one variable"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-UtLy5ew2Hj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "625be2ad-3538-462e-996a-9f51b36e9ad5"
      },
      "source": [
        "\n",
        "set2.update(a)\n",
        "\n",
        "print(set2)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'table', 'of', 'search', 'elements', 'a', 'found', 'setups', 'which', 'content', 'not', 'we', 'learn', 'than', 'many', 'this', 'examples', 'valueerror', 'websites', 'to', 'requires', 'searches', 'often', 'any', 'lot', 'beautifulsoup', 'come', 'how', 'therefore', '“valueerror', 'article', 'nanoscale', 'because', 'client', 'more', 'required', 'webpages', 'error', 'example', 'advances', 'collecting', 'from', 'without', 'python', 'shows', 'scrapping', 'has', 'extra', 'modern', 'in', 'selenium', 'use', 'webpage', 'parsing', 'tools', 'readhtml', 'no', 'result', 'found”', 'pandas', 'published', 'journal', 'you’ll', 'web', 'and', 'want', 'goal', 'however', 'for', 'tables', 'is', 'let’s', '0', 'source', 'the', 'are', 'can’t', 'look', 'take', 'scrape', 'powerful', 'following', 'page', 'community', 'process', 'it', 'an', 'using', 'scraping', 'data', 'javascript', 'will', 'work', 'up', 'function', 'at', 'dynamic', 'pretty', 'loaded', 'some', 'populated', 'script', 'find', 'with', 'suppose', 'order', 'reach', 'running', 'if'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zLrVkd_zw2h-"
      },
      "source": [
        "12. from the new variable, remove all values that start with \"t\" or its lengh is greater 8"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1rgebJzDxFCO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9eecf6ab-5d11-40ff-b8ca-48f627ad885b"
      },
      "source": [
        "\n",
        "\n",
        "f = []\n",
        "\n",
        "for e in set2:\n",
        "  if not e.startswith(\"t\") and len(e) < 8:\n",
        "    f.append(e)\n",
        "\n",
        "\n",
        "print(f)\n",
        "\n"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['of', 'search', 'a', 'found', 'setups', 'which', 'content', 'not', 'we', 'learn', 'many', 'often', 'any', 'lot', 'come', 'how', 'article', 'because', 'client', 'more', 'error', 'example', 'from', 'without', 'python', 'shows', 'has', 'extra', 'modern', 'in', 'use', 'webpage', 'parsing', 'no', 'result', 'found”', 'pandas', 'journal', 'you’ll', 'web', 'and', 'want', 'goal', 'however', 'for', 'is', 'let’s', '0', 'source', 'are', 'can’t', 'look', 'scrape', 'page', 'process', 'it', 'an', 'using', 'data', 'will', 'work', 'up', 'at', 'dynamic', 'pretty', 'loaded', 'some', 'script', 'find', 'with', 'suppose', 'order', 'reach', 'running', 'if']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WwR05febHXWb",
        "outputId": "b9ecd9d5-9e74-415f-f56d-68b274d2c75e"
      },
      "source": [
        "m = sorted(f)\n",
        "\n",
        "\n",
        "print(m)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['0', 'a', 'an', 'and', 'any', 'are', 'article', 'at', 'because', 'can’t', 'client', 'come', 'content', 'data', 'dynamic', 'error', 'example', 'extra', 'find', 'for', 'found', 'found”', 'from', 'goal', 'has', 'how', 'however', 'if', 'in', 'is', 'it', 'journal', 'learn', 'let’s', 'loaded', 'look', 'lot', 'many', 'modern', 'more', 'no', 'not', 'of', 'often', 'order', 'page', 'pandas', 'parsing', 'pretty', 'process', 'python', 'reach', 'result', 'running', 'scrape', 'script', 'search', 'setups', 'shows', 'some', 'source', 'suppose', 'up', 'use', 'using', 'want', 'we', 'web', 'webpage', 'which', 'will', 'with', 'without', 'work', 'you’ll']\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}